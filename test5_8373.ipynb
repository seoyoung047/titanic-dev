{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 함수 모음\n",
    "\n",
    "## train, test 불러오기\n",
    "def load_traintest_dt():\n",
    "    train = pd.read_csv('../data/titanic/train.csv')\n",
    "    test = pd.read_csv('../data/titanic/test.csv')  \n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "## submission_a 불러오기\n",
    "def load_submission_a() :\n",
    "    submission_a = pd.read_csv('../data/submission_a.csv')\n",
    "    del submission_a['PassengerId']\n",
    "\n",
    "    return submission_a\n",
    "\n",
    "## 피처 삭제\n",
    "def drop_col(train,test,col_list):\n",
    "    '''\n",
    "    drop train, test column\n",
    "    parameter : train,test, list\n",
    "    return train,test\n",
    "    '''\n",
    "    train = train.drop(col_list,axis=1)\n",
    "    test = test.drop(col_list, axis=1)\n",
    "    return (train,test)\n",
    "\n",
    "## train, target 나누기\n",
    "def split_data(train):\n",
    "    train_data = train.drop('Survived',axis=1)\n",
    "    target = train['Survived']\n",
    "\n",
    "    return (train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "\n",
    "    # Name,Title\n",
    "def Name_cleaning(train,test):\n",
    "    \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "\n",
    "    train_title_mapping = {'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3\n",
    "                    , 'Dr':4, 'Rev':4, 'Mlle':4, 'Major':4, 'Col':4\n",
    "                    ,'Countess':4, 'Capt':4, 'Ms':4, 'Sir':4, 'Lady':4\n",
    "                    , 'Mme':4, 'Don':4, 'Jonkheer':4\n",
    "                    }\n",
    "    train['Title'] = train['Title'].map(train_title_mapping)\n",
    "\n",
    "    test_title_mapping = {'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3\n",
    "                    , 'Col':4, 'Rev':4, 'Ms':4, 'Dr':4, 'Dona':4\n",
    "                    }\n",
    "\n",
    "    test['Title'] = test['Title'].map(test_title_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # sex\n",
    "def sex_cleaning(train,test):\n",
    "    sex_mapping = {'male':0, 'female':1}\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset['Sex'] = dataset['Sex'].map(sex_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # Have Age\n",
    "def haveage_cleaning(train,test):\n",
    "\n",
    "    train.loc[train['Age'].isnull(), 'Null_Age'] = 0\n",
    "    test.loc[test['Age'].isnull(), 'Null_Age'] = 0\n",
    "\n",
    "    train.loc[train['Age'].notnull(), 'Null_Age'] = 1\n",
    "    test.loc[test['Age'].notnull(), 'Null_Age'] = 1\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "\n",
    "    # Age\n",
    "def age_cleaning(train,test):\n",
    "    \n",
    "    train['Age'].fillna(train.groupby('Title')['Age'].transform('mean'),inplace=True)\n",
    "    test['Age'].fillna(test.groupby('Title')['Age'].transform('mean'),inplace=True)\n",
    "\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset.loc[dataset['Age'] <= 17, 'Age'] =0\n",
    "        dataset.loc[(dataset['Age'] >17) & (dataset['Age'] <= 24), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] >24) & (dataset['Age'] <= 34), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] >34) & (dataset['Age'] <= 44), 'Age'] = 3\n",
    "        dataset.loc[(dataset['Age'] >44) & (dataset['Age'] <= 60), 'Age'] = 4\n",
    "        dataset.loc[dataset['Age'] >60, 'Age'] = 5\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "\n",
    "    # Embarked\n",
    "def embarked_cleaning(train,test):\n",
    "\n",
    "    train['Embarked'] = train['Embarked'].fillna('S')\n",
    "    test['Embarked'] = test['Embarked'].fillna('S')\n",
    "\n",
    "    embarked_mapping = {'S':0, 'C':1, 'Q':2}\n",
    "    train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "    test['Embarked'] = test['Embarked'].map(embarked_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    #Fare\n",
    "def fare_cleaning(train,test):\n",
    "\n",
    "    test['Fare'].fillna(\n",
    "        test.groupby('Pclass')['Fare'].transform('median'), inplace=True\n",
    "    )\n",
    "    #############################################################################\n",
    "    \n",
    "    train.loc[train['Fare'] == 0, 'Zero_Fare'] = 0\n",
    "    test.loc[test['Fare'] == 0, 'Zero_Fare'] = 0\n",
    "\n",
    "    train.loc[train['Fare'] != 0, 'Zero_Fare'] = 1\n",
    "    test.loc[test['Fare'] != 0, 'Zero_Fare'] = 1\n",
    "\n",
    "\n",
    "    ##############################################################################\n",
    "    \n",
    "    return (train,test)\n",
    "\n",
    "    # group_size\n",
    "def groupsize_cleanig(train,test):\n",
    "\n",
    "    for ticket_num in train['Ticket'].unique():\n",
    "        train.loc[train['Ticket']==ticket_num,'group_size'] = len(train[train['Ticket']==ticket_num])\n",
    "\n",
    "    for ticket_num in test['Ticket'].unique():\n",
    "        test.loc[test['Ticket']==ticket_num,'group_size'] = len(test[test['Ticket']==ticket_num])\n",
    "\n",
    "    train['Fare'] = train['Fare']/train['group_size']\n",
    "    test['Fare'] = test['Fare']/test['group_size']\n",
    "    \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset.loc[dataset['group_size'] == 1, 'group_size'] = 0\n",
    "        dataset.loc[dataset['group_size'] == 2, 'group_size'] = 0.4\n",
    "        dataset.loc[(dataset['group_size'] == 3) | (dataset['group_size'] == 4), 'group_size'] = 0.8\n",
    "        dataset.loc[dataset['group_size'] > 4, 'group_size'] = 1.2\n",
    "\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "\n",
    "        dataset.loc[dataset['Fare'] <= 7,'Fare'] = 0\n",
    "        dataset.loc[(dataset['Fare'] >7) & (dataset['Fare'] <=8.8), 'Fare'] = 0.4\n",
    "        dataset.loc[(dataset['Fare'] >8.8) & (dataset['Fare'] <=17), 'Fare'] = 0.8\n",
    "        dataset.loc[(dataset['Fare'] >17) & (dataset['Fare'] <=30), 'Fare'] = 1.2\n",
    "        dataset.loc[(dataset['Fare'] >30) & (dataset['Fare'] <=100), 'Fare'] = 1.6\n",
    "        dataset.loc[dataset['Fare'] > 100,'Fare'] = 2\n",
    "        \n",
    "    return (train,test)\n",
    "\n",
    "    # Have Cabin\n",
    "def havecabin_cleaning(train,test):\n",
    "\n",
    "    train.loc[train['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "    test.loc[test['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "\n",
    "    train.loc[train['Cabin'].notnull(), 'Null_Cabin'] = 1\n",
    "    test.loc[test['Cabin'].notnull(), 'Null_Cabin'] = 1\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # Cabin\n",
    "def cabin_cleaning(train,test):\n",
    "\n",
    "    train['Cabin'] = train['Cabin'].str[:1]\n",
    "    test['Cabin'] = test['Cabin'].str[:1]\n",
    "\n",
    "    cabin_mapping = {\"A\": 0, \"B\": 0.4\n",
    "                    , \"C\": 0.8, \"D\": 1.2\n",
    "                    , \"E\": 1.6, \"F\": 2, \"G\": 2.4\n",
    "                    , 'T' :2.8\n",
    "                    }\n",
    "\n",
    "    train['Cabin'] = train['Cabin'].map(cabin_mapping)\n",
    "    test['Cabin'] = test['Cabin'].map(cabin_mapping)\n",
    "\n",
    "    train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "    test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # FamilySize\n",
    "def familysize_cleaning(train,test):\n",
    "\n",
    "    train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "    test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "    family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "    train['FamilySize'] = train['FamilySize'].map(family_mapping)\n",
    "    test['FamilySize'] = test['FamilySize'].map(family_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # 정규화\n",
    "def data_scaler(train,test):\n",
    "\n",
    "    columns = ['Pclass', 'Sex', 'Age', 'Fare', 'Cabin',\n",
    "        'Embarked', 'Title'\n",
    "        , 'group_size'\n",
    "        ,'FamilySize','Family_Survival'\n",
    "        # , 'Null_Cabin'\n",
    "        # , 'Null_Age'\n",
    "        # ,'Zero_Fare'\n",
    "        ]\n",
    " \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        scaler = MinMaxScaler()\n",
    "        # scaler = StandardScaler()\n",
    "\n",
    "        scaler.fit(dataset[columns])\n",
    "        scaled = scaler.transform(dataset[columns])\n",
    "\n",
    "        df_scaled = pd.DataFrame(data=scaled, columns=columns)\n",
    "        dataset.loc[:,columns] = df_scaled\n",
    "\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 전체 실행\n",
    "\n",
    "def data_cleaning():\n",
    "    train,test = load_traintest_dt()\n",
    "\n",
    "    #name\n",
    "    train,test = Name_cleaning(train,test)\n",
    "    #sex\n",
    "    train,test = sex_cleaning(train,test)\n",
    "    #haveage\n",
    "    train,test = haveage_cleaning(train,test)\n",
    "    #age\n",
    "    train,test = age_cleaning(train,test)\n",
    "    #embarked\n",
    "    train,test = embarked_cleaning(train,test)\n",
    "    #fare\n",
    "    train,test = fare_cleaning(train,test)\n",
    "    #groupsize\n",
    "    train,test = groupsize_cleanig(train,test)\n",
    "    #havecabin\n",
    "    train,test = havecabin_cleaning(train,test)\n",
    "    #cabin\n",
    "    train,test = cabin_cleaning(train,test)\n",
    "    #familysize\n",
    "    train,test = familysize_cleaning(train,test)\n",
    "    \n",
    "    #scaler\n",
    "    train,test = data_scaler(train,test)\n",
    "\n",
    "    #drop\n",
    "    train,test = drop_col(train,test,['Ticket','SibSp','Parch','Name'])\n",
    "\n",
    "    #split\n",
    "\n",
    "    train_data, target = split_data(train)\n",
    "\n",
    "    return (train_data,target,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test = load_traintest_dt()\n",
    "\n",
    "# #name\n",
    "# train,test = Name_cleaning(train,test)\n",
    "# #sex\n",
    "# train,test = sex_cleaning(train,test)\n",
    "# #haveage\n",
    "# train,test = haveage_cleaning(train,test)\n",
    "# #age\n",
    "# train,test = age_cleaning(train,test)\n",
    "# #embarked\n",
    "# train,test = embarked_cleaning(train,test)\n",
    "# #fare\n",
    "# train,test = fare_cleaning(train,test)\n",
    "# #groupsize\n",
    "# train,test = groupsize_cleanig(train,test)\n",
    "# #havecabin\n",
    "# train,test = havecabin_cleaning(train,test)\n",
    "# #cabin\n",
    "# train,test = cabin_cleaning(train,test)\n",
    "# #familysize\n",
    "# train,test = familysize_cleaning(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = load_traintest_dt()\n",
    "data_df = pd.concat([train,test])\n",
    "#name\n",
    "train,test = Name_cleaning(train,test)\n",
    "#sex\n",
    "train,test = sex_cleaning(train,test)\n",
    "#groupsize\n",
    "train,test = groupsize_cleanig(train,test)\n",
    "#haveage\n",
    "train,test = haveage_cleaning(train,test)\n",
    "#age\n",
    "train,test = age_cleaning(train,test)\n",
    "#embarked\n",
    "train,test = embarked_cleaning(train,test)\n",
    "#fare\n",
    "train,test = fare_cleaning(train,test)\n",
    "#havecabin\n",
    "train,test = havecabin_cleaning(train,test)\n",
    "#cabin\n",
    "train,test = cabin_cleaning(train,test)\n",
    "#familysize\n",
    "train,test = familysize_cleaning(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_df['Lastname'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "# data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Lastname', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Lastname', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passenger with family/group survival information: 546\n"
     ]
    }
   ],
   "source": [
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))\n",
    "\n",
    "# # Family_Survival in TRAIN_DF and TEST_DF:\n",
    "train['Family_Survival'] = data_df['Family_Survival'][:891]\n",
    "test['Family_Survival'] = data_df['Family_Survival'][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop\n",
    "train,test = drop_col(train,test,['Ticket','SibSp','Parch','Name'\n",
    "                                  \n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>group_size</th>\n",
       "      <th>Null_Age</th>\n",
       "      <th>Zero_Fare</th>\n",
       "      <th>Null_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Family_Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  Fare  Cabin  Embarked  Title   \n",
       "0            1         0       3    0  1.0   0.4    2.0         0      0  \\\n",
       "1            2         1       1    1  3.0   1.6    0.8         1      2   \n",
       "2            3         1       3    1  2.0   0.4    2.0         0      1   \n",
       "3            4         1       1    1  3.0   1.2    0.8         0      2   \n",
       "4            5         0       3    0  3.0   0.4    2.0         0      0   \n",
       "\n",
       "   group_size  Null_Age  Zero_Fare  Null_Cabin  FamilySize  Family_Survival  \n",
       "0         0.0       1.0        1.0         0.0         0.4              0.5  \n",
       "1         0.0       1.0        1.0         1.0         0.4              0.5  \n",
       "2         0.0       1.0        1.0         0.0         0.0              0.5  \n",
       "3         0.4       1.0        1.0         1.0         0.4              0.0  \n",
       "4         0.0       1.0        1.0         0.0         0.0              0.5  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Cabin',\n",
    "       'Embarked', 'Title', 'group_size',\n",
    "       'FamilySize', 'Family_Survival']]\n",
    "test = test[['PassengerId', 'Pclass', 'Sex', 'Age', 'Fare', 'Cabin', 'Embarked',\n",
    "       'Title', 'group_size', 'FamilySize',\n",
    "       'Family_Survival']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "# # alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환 \n",
    "# def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, \n",
    "#                         verbose=True, return_coeff=True):\n",
    "#     coeff_df = pd.DataFrame()\n",
    "#     if verbose : print('####### ', model_name , '#######')\n",
    "#     for param in params:\n",
    "#         if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "#         elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "#         elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "#         neg_mse_scores = cross_val_score(model, X_data_n, \n",
    "#                                              y_target_n, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "#         avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "#         print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f} '.format(param, avg_rmse))\n",
    "#         # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
    "        \n",
    "#         model.fit(X_data_n , y_target_n)\n",
    "#         if return_coeff:\n",
    "#             # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가. \n",
    "#             coeff = pd.Series(data=model.coef_ , index=X_data_n.columns )\n",
    "#             colname='alpha:'+str(param)\n",
    "#             coeff_df[colname] = coeff\n",
    "    \n",
    "#     return coeff_df\n",
    "# # end of get_linear_regre_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "#     if method=='Standard':\n",
    "#         scaled_data = StandardScaler().fit_transform(input_data)\n",
    "#     elif method =='MinMax':\n",
    "#         scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "#     elif method == 'Log':\n",
    "#         scaled_data = np.log1p(input_data)\n",
    "#     else:\n",
    "#         scaled_data = input_data\n",
    "\n",
    "#     if p_degree != None:\n",
    "#         scaled_data = PolynomialFeatures(degree=p_degree\n",
    "#                                          ,include_bias=False\n",
    "#                                          ).fit_transform(scaled_data)\n",
    "\n",
    "#     return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = [0.1,1,10,100]\n",
    "\n",
    "# scale_methods = [(None,None),('Standard',None),('Standard',2),\n",
    "#                  ('MinMax',None),('MinMax',2),('Log',None)]\n",
    "\n",
    "# for scale_method in scale_methods:\n",
    "#     X_data_scaled = get_scaled_data(method=scale_methods[0]\n",
    "#                                     ,p_degree=scale_method[1]\n",
    "#                                     ,input_data=train_data)\n",
    "#     print('\\n ## 변환유형:{0}, Poynomial Degree:{1}'.format(scale_method[0]\n",
    "#                                                         ,scale_method[1]))\n",
    "#     get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled\n",
    "#                         , y_target_n=target, verbose=False, return_coeff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data_scaler(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, target = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>group_size</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Family_Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.390348</td>\n",
       "      <td>0.365657</td>\n",
       "      <td>0.596280</td>\n",
       "      <td>0.180696</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>0.090460</td>\n",
       "      <td>0.519641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.418036</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.248585</td>\n",
       "      <td>0.246388</td>\n",
       "      <td>0.192977</td>\n",
       "      <td>0.317837</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>0.299548</td>\n",
       "      <td>0.161346</td>\n",
       "      <td>0.323961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Sex         Age   \n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  \\\n",
       "mean    446.000000    0.383838    0.654321    0.352413    0.390348   \n",
       "std     257.353842    0.486592    0.418036    0.477990    0.248585   \n",
       "min       1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     223.500000    0.000000    0.500000    0.000000    0.200000   \n",
       "50%     446.000000    0.000000    1.000000    0.000000    0.400000   \n",
       "75%     668.500000    1.000000    1.000000    1.000000    0.600000   \n",
       "max     891.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             Fare       Cabin    Embarked       Title  group_size  FamilySize   \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  \\\n",
       "mean     0.365657    0.596280    0.180696    0.185185    0.205387    0.090460   \n",
       "std      0.246388    0.192977    0.317837    0.263019    0.299548    0.161346   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.200000    0.571429    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.400000    0.714286    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.600000    0.714286    0.500000    0.250000    0.333333    0.100000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Family_Survival  \n",
       "count       891.000000  \n",
       "mean          0.519641  \n",
       "std           0.323961  \n",
       "min           0.000000  \n",
       "25%           0.500000  \n",
       "50%           0.500000  \n",
       "75%           0.500000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_a = load_submission_a()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373205741626795"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "                            max_depth=5\n",
    "                              ,n_estimators=57\n",
    "                             ,min_samples_leaf=45\n",
    "                             , random_state=228\n",
    "                             ,n_jobs=-1\n",
    "                             )\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "prediction = clf.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(prediction, submission_a)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "\n",
    "    'PassengerId':test['PassengerId']\n",
    "    ,'Survived':prediction\n",
    "    \n",
    "})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.8157894736842105)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
