{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 함수 모음\n",
    "\n",
    "## train, test 불러오기\n",
    "def load_traintest_dt():\n",
    "    train = pd.read_csv('../data/titanic/train.csv')\n",
    "    test = pd.read_csv('../data/titanic/test.csv')  \n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "## submission_a 불러오기\n",
    "def load_submission_a() :\n",
    "    submission_a = pd.read_csv('../data/submission_a.csv')\n",
    "    del submission_a['PassengerId']\n",
    "\n",
    "    return submission_a\n",
    "\n",
    "## 피처 삭제\n",
    "def drop_col(train,test,col_list):\n",
    "    '''\n",
    "    drop train, test column\n",
    "    parameter : train,test, list\n",
    "    return train,test\n",
    "    '''\n",
    "    train = train.drop(col_list,axis=1)\n",
    "    test = test.drop(col_list, axis=1)\n",
    "    return (train,test)\n",
    "\n",
    "## train, target 나누기\n",
    "def split_data(train):\n",
    "    train_data = train.drop('Survived',axis=1)\n",
    "    target = train['Survived']\n",
    "\n",
    "    return (train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "\n",
    "    # Name,Title\n",
    "def Name_cleaning(train,test):\n",
    "    \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "\n",
    "    train_title_mapping = {'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3\n",
    "                    , 'Dr':4, 'Rev':4, 'Mlle':4, 'Major':4, 'Col':4\n",
    "                    ,'Countess':4, 'Capt':4, 'Ms':4, 'Sir':4, 'Lady':4\n",
    "                    , 'Mme':4, 'Don':4, 'Jonkheer':4\n",
    "                    }\n",
    "    train['Title'] = train['Title'].map(train_title_mapping)\n",
    "\n",
    "    test_title_mapping = {'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3\n",
    "                    , 'Col':4, 'Rev':4, 'Ms':4, 'Dr':4, 'Dona':4\n",
    "                    }\n",
    "\n",
    "    test['Title'] = test['Title'].map(test_title_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # sex\n",
    "def sex_cleaning(train,test):\n",
    "    sex_mapping = {'male':0, 'female':1}\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset['Sex'] = dataset['Sex'].map(sex_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # Have Age\n",
    "def haveage_cleaning(train,test):\n",
    "\n",
    "    train.loc[train['Age'].isnull(), 'Null_Age'] = 0\n",
    "    test.loc[test['Age'].isnull(), 'Null_Age'] = 0\n",
    "\n",
    "    train.loc[train['Age'].notnull(), 'Null_Age'] = 1\n",
    "    test.loc[test['Age'].notnull(), 'Null_Age'] = 1\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "\n",
    "    # Age\n",
    "def age_cleaning(train,test):\n",
    "    \n",
    "    # train['Age'].fillna(train.groupby('Title')['Age'].transform('mean'),inplace=True)\n",
    "    # test['Age'].fillna(test.groupby('Title')['Age'].transform('mean'),inplace=True)\n",
    "\n",
    "    train['Age'] = train.groupby(['Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "    test['Age'] = test.groupby(['Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset.loc[dataset['Age'] <= 17, 'Age'] =0\n",
    "        dataset.loc[(dataset['Age'] >17) & (dataset['Age'] <= 24), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] >24) & (dataset['Age'] <= 34), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] >34) & (dataset['Age'] <= 44), 'Age'] = 3\n",
    "        dataset.loc[(dataset['Age'] >44) & (dataset['Age'] <= 60), 'Age'] = 4\n",
    "        dataset.loc[dataset['Age'] >60, 'Age'] = 5\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "\n",
    "    # Embarked\n",
    "def embarked_cleaning(train,test):\n",
    "\n",
    "    train['Embarked'] = train['Embarked'].fillna('S')\n",
    "    test['Embarked'] = test['Embarked'].fillna('S')\n",
    "\n",
    "    embarked_mapping = {'S':0, 'C':1, 'Q':2}\n",
    "    train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "    test['Embarked'] = test['Embarked'].map(embarked_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    #Fare\n",
    "def fare_cleaning(train,test):\n",
    "\n",
    "    test['Fare'].fillna(\n",
    "        test.groupby('Pclass')['Fare'].transform('median'), inplace=True\n",
    "    )\n",
    "    \n",
    "    train.loc[train['Fare'] == 0, 'Zero_Fare'] = 0\n",
    "    test.loc[test['Fare'] == 0, 'Zero_Fare'] = 0\n",
    "\n",
    "    train.loc[train['Fare'] != 0, 'Zero_Fare'] = 1\n",
    "    test.loc[test['Fare'] != 0, 'Zero_Fare'] = 1\n",
    "\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # group_size\n",
    "def groupsize_cleanig(train,test):\n",
    "\n",
    "    for ticket_num in train['Ticket'].unique():\n",
    "        train.loc[train['Ticket']==ticket_num,'group_size'] = len(train[train['Ticket']==ticket_num])\n",
    "\n",
    "    for ticket_num in test['Ticket'].unique():\n",
    "        test.loc[test['Ticket']==ticket_num,'group_size'] = len(test[test['Ticket']==ticket_num])\n",
    "\n",
    "    train['Fare'] = train['Fare']/train['group_size']\n",
    "    test['Fare'] = test['Fare']/test['group_size']\n",
    "    \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        dataset.loc[dataset['group_size'] == 1, 'group_size'] = 0\n",
    "        dataset.loc[dataset['group_size'] == 2, 'group_size'] = 0.4\n",
    "        dataset.loc[(dataset['group_size'] == 3) | (dataset['group_size'] == 4), 'group_size'] = 0.8\n",
    "        dataset.loc[dataset['group_size'] > 4, 'group_size'] = 1.2\n",
    "\n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "\n",
    "        dataset.loc[dataset['Fare'] <= 7,'Fare'] = 0\n",
    "        dataset.loc[(dataset['Fare'] >7) & (dataset['Fare'] <=8.8), 'Fare'] = 0.4\n",
    "        dataset.loc[(dataset['Fare'] >8.8) & (dataset['Fare'] <=17), 'Fare'] = 0.8\n",
    "        dataset.loc[(dataset['Fare'] >17) & (dataset['Fare'] <=30), 'Fare'] = 1.2\n",
    "        dataset.loc[(dataset['Fare'] >30) & (dataset['Fare'] <=100), 'Fare'] = 1.6\n",
    "        dataset.loc[dataset['Fare'] > 100,'Fare'] = 2\n",
    "        \n",
    "    return (train,test)\n",
    "\n",
    "    # Have Cabin\n",
    "def havecabin_cleaning(train,test):\n",
    "\n",
    "    train.loc[train['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "    test.loc[test['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "\n",
    "    train.loc[train['Cabin'].notnull(), 'Null_Cabin'] = 1\n",
    "    test.loc[test['Cabin'].notnull(), 'Null_Cabin'] = 1\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # Cabin\n",
    "def cabin_cleaning(train,test):\n",
    "\n",
    "    train['Cabin'] = train['Cabin'].str[:1]\n",
    "    test['Cabin'] = test['Cabin'].str[:1]\n",
    "\n",
    "    cabin_mapping = {\"A\": 0, \"B\": 0.4\n",
    "                    , \"C\": 0.8, \"D\": 1.2\n",
    "                    , \"E\": 1.6, \"F\": 2, \"G\": 2.4\n",
    "                    , 'T' :2.8\n",
    "                    }\n",
    "\n",
    "    train['Cabin'] = train['Cabin'].map(cabin_mapping)\n",
    "    test['Cabin'] = test['Cabin'].map(cabin_mapping)\n",
    "\n",
    "    train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "    test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # FamilySize\n",
    "def familysize_cleaning(train,test):\n",
    "\n",
    "    train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "    test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "    family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "    train['FamilySize'] = train['FamilySize'].map(family_mapping)\n",
    "    test['FamilySize'] = test['FamilySize'].map(family_mapping)\n",
    "\n",
    "    return (train,test)\n",
    "\n",
    "    # 정규화\n",
    "def data_scaler(train,test,columns):\n",
    " \n",
    "    train_test_data = [train,test]\n",
    "    for dataset in train_test_data:\n",
    "        scaler = MinMaxScaler()\n",
    "        # scaler = StandardScaler()\n",
    "\n",
    "        scaler.fit(dataset[columns])\n",
    "        scaled = scaler.transform(dataset[columns])\n",
    "\n",
    "        df_scaled = pd.DataFrame(data=scaled, columns=columns)\n",
    "        dataset.loc[:,columns] = df_scaled\n",
    "\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Family_Survival(data_df,train,test):\n",
    "\n",
    "\n",
    "    data_df['Lastname'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "    DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "    data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "    for grp, grp_df in data_df[['Survived','Name', 'Lastname', 'Fare', 'Ticket', 'PassengerId',\n",
    "                            'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Lastname', 'Fare']):\n",
    "        \n",
    "        if (len(grp_df) != 1):\n",
    "            # A Family group is found.\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "    for _, grp_df in data_df.groupby('Ticket'):\n",
    "        if (len(grp_df) != 1):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                    smax = grp_df.drop(ind)['Survived'].max()\n",
    "                    smin = grp_df.drop(ind)['Survived'].min()\n",
    "                    passID = row['PassengerId']\n",
    "                    if (smax == 1.0):\n",
    "                        data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                    elif (smin==0.0):\n",
    "                        data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "    # # Family_Survival in TRAIN_DF and TEST_DF:\n",
    "    train['Family_Survival'] = data_df['Family_Survival'][:891]\n",
    "    test['Family_Survival'] = data_df['Family_Survival'][891:]\n",
    "\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = load_traintest_dt()\n",
    "data_df = pd.concat([train,test])\n",
    "\n",
    "train,test = Name_cleaning(train,test)\n",
    "#sex\n",
    "train,test = sex_cleaning(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title  Pclass     \n",
       "0      1       6      54.0\n",
       "               23     28.0\n",
       "               27     19.0\n",
       "               34     28.0\n",
       "               35     42.0\n",
       "                      ... \n",
       "4      2       398    23.0\n",
       "               443    28.0\n",
       "               626    57.0\n",
       "               848    28.0\n",
       "               886    27.0\n",
       "Name: Age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "# test['Age'] = test.groupby(['Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8373\n",
    "\n",
    "def data_cleaning():\n",
    "    train,test = load_traintest_dt()\n",
    "    data_df = pd.concat([train,test])\n",
    "    \n",
    "    #name\n",
    "    train,test = Name_cleaning(train,test)\n",
    "    #sex\n",
    "    train,test = sex_cleaning(train,test)\n",
    "    #haveage\n",
    "    train,test = haveage_cleaning(train,test)\n",
    "    #embarked\n",
    "    train,test = embarked_cleaning(train,test)\n",
    "    #fare\n",
    "    train,test = fare_cleaning(train,test)\n",
    "    #groupsize\n",
    "    train,test = groupsize_cleanig(train,test)\n",
    "    #havecabin\n",
    "    train,test = havecabin_cleaning(train,test)\n",
    "    #cabin\n",
    "    train,test = cabin_cleaning(train,test)\n",
    "    #age\n",
    "    train,test = age_cleaning(train,test)\n",
    "    #familysize\n",
    "    train,test = familysize_cleaning(train,test)\n",
    "    \n",
    "    #familysurvival\n",
    "    data_df = Family_Survival(data_df,train,test)\n",
    "\n",
    "\n",
    "    #drop\n",
    "    train,test = drop_col(train,test,['Ticket','SibSp','Parch','Name'])\n",
    "\n",
    "    # 컬럼 순서 조정\n",
    "    train = train[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Cabin',\n",
    "       'Embarked', 'Title', 'group_size',\n",
    "       'FamilySize', 'Family_Survival']]\n",
    "    test = test[['PassengerId', 'Pclass', 'Sex', 'Age', 'Fare', 'Cabin', 'Embarked',\n",
    "        'Title', 'group_size', 'FamilySize',\n",
    "        'Family_Survival']]\n",
    "    #scaler\n",
    "    columns = ['Pclass', 'Sex','Age'\n",
    "               , 'Fare', 'Cabin'\n",
    "               , 'Embarked', 'Title'\n",
    "                , 'group_size'\n",
    "                ,'FamilySize','Family_Survival'\n",
    "                ]\n",
    "    train,test = data_scaler(train,test,columns)\n",
    "\n",
    "    #split\n",
    "\n",
    "    train_data, target = split_data(train)\n",
    "\n",
    "    return (train_data, target,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "incompatible index of inserted column with frame index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\frame.py:11615\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  11614\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m> 11615\u001b[0m     reindexed_value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreindex(index)\u001b[39m.\u001b[39m_values\n\u001b[0;32m  11616\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m  11617\u001b[0m     \u001b[39m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\series.py:4914\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4897\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m   4898\u001b[0m     NDFrame\u001b[39m.\u001b[39mreindex,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4899\u001b[0m     klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     tolerance\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   4913\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[1;32m-> 4914\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreindex(\n\u001b[0;32m   4915\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4916\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   4917\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   4918\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4919\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   4920\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   4921\u001b[0m         tolerance\u001b[39m=\u001b[39;49mtolerance,\n\u001b[0;32m   4922\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\generic.py:5360\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[0;32m   5361\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5362\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\generic.py:5375\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5374\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5375\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mreindex(\n\u001b[0;32m   5376\u001b[0m     labels, level\u001b[39m=\u001b[39;49mlevel, limit\u001b[39m=\u001b[39;49mlimit, tolerance\u001b[39m=\u001b[39;49mtolerance, method\u001b[39m=\u001b[39;49mmethod\n\u001b[0;32m   5377\u001b[0m )\n\u001b[0;32m   5379\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4278\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4276\u001b[0m             indexer, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m-> 4278\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_reindex_result(target, indexer, preserve_names)\n\u001b[0;32m   4279\u001b[0m \u001b[39mreturn\u001b[39;00m target, indexer\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:2490\u001b[0m, in \u001b[0;36mMultiIndex._wrap_reindex_result\u001b[1;34m(self, target, indexer, preserve_names)\u001b[0m\n\u001b[0;32m   2489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2490\u001b[0m     target \u001b[39m=\u001b[39m MultiIndex\u001b[39m.\u001b[39;49mfrom_tuples(target)\n\u001b[0;32m   2491\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   2492\u001b[0m     \u001b[39m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:211\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[1;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m meth(self_or_cls, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:590\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[1;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[0;32m    588\u001b[0m         tuples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(tuples\u001b[39m.\u001b[39m_values)\n\u001b[1;32m--> 590\u001b[0m     arrays \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(lib\u001b[39m.\u001b[39;49mtuples_to_object_array(tuples)\u001b[39m.\u001b[39mT)\n\u001b[0;32m    591\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(tuples, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2894\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long long'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6880\\1316704223.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6880\\647935367.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhavecabin_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#cabin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcabin_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mage_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;31m#familysize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfamilysize_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6880\\1799323676.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# train['Age'].fillna(train.groupby('Title')['Age'].transform('mean'),inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# test['Age'].fillna(test.groupby('Title')['Age'].transform('mean'),inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mtrain_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3956\u001b[0m             \u001b[1;31m# Column to set is duplicated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3957\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3958\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3959\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3960\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4150\u001b[0m         \u001b[0mSeries\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mTimeSeries\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconformed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrames\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \"\"\"\n\u001b[1;32m-> 4153\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         if (\n\u001b[0;32m   4156\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4873\u001b[0m         \u001b[1;31m# or through loc single_block_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4875\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4876\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4877\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4879\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4880\u001b[0m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  11618\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11619\u001b[0m             \u001b[1;31m# duplicate axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11620\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11622\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m  11623\u001b[0m             \u001b[1;34m\"incompatible index of inserted column with frame index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11624\u001b[0m         ) from err\n\u001b[0;32m  11625\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreindexed_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: incompatible index of inserted column with frame index"
     ]
    }
   ],
   "source": [
    "train_data, target, test = data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_a = load_submission_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373205741626795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8373\n",
    "clf = RandomForestClassifier(\n",
    "                            max_depth=5\n",
    "                              ,n_estimators=57\n",
    "                             ,min_samples_leaf=45\n",
    "                             , random_state=228\n",
    "                             ,n_jobs=-1\n",
    "                             )\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "prediction = clf.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(prediction, submission_a)\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
