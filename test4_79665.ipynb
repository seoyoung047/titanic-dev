{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name | Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train,test]\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.',expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {'Mr':1.6, 'Miss':0.4, 'Mrs':0.8, 'Master':1.2\n",
    "                 , 'Dr':0, 'Rev':0, 'Mlle':0, 'Major':0, 'Col':0\n",
    "                 ,'Countess':0, 'Capt':0, 'Ms':0, 'Sir':0, 'Lady':0\n",
    "                 , 'Mme':0, 'Don':0, 'Jonkheer':0\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {'Mr':1.6, 'Miss':0.4, 'Mrs':0.8, 'Master':1.2\n",
    "                 , 'Col':0, 'Rev':0, 'Ms':0, 'Dr':0, 'Dona':0\n",
    "                 }\n",
    "\n",
    "test['Title'] = test['Title'].map(title_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {'male':0, 'female':1}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(sex_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hase Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Age'].isnull(), 'Null_Age'] = 0\n",
    "test.loc[test['Age'].isnull(), 'Null_Age'] = 0\n",
    "\n",
    "train.loc[train['Age'].notnull(), 'Null_Age'] = 1\n",
    "test.loc[test['Age'].notnull(), 'Null_Age'] = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing age with median age for each title(Mr,Mrs,Miss,Master,Others)\n",
    "# Age 결측치 해당 Title의 나이의 중앙값으로 채우기\n",
    "\n",
    "train['Age'].fillna(train.groupby('Title')['Age'].transform('median'),inplace=True)\n",
    "test['Age'].fillna(test.groupby('Title')['Age'].transform('median'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Null_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   \n",
       "0            1         0       3  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex  Age  SibSp  Parch   \n",
       "0                            Braund, Mr. Owen Harris    0  1.2      1      0  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  2.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  1.2      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  2.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  2.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Title  Null_Age  \n",
       "0         A/5 21171   7.2500   NaN        S      3       1.0  \n",
       "1          PC 17599  71.2833   C85        C      2       1.0  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S      1       1.0  \n",
       "3            113803  53.1000  C123        S      2       1.0  \n",
       "4            373450   8.0500   NaN        S      3       1.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[dataset['Age'] <= 10, 'Age'] =0\n",
    "    dataset.loc[(dataset['Age'] >10) & (dataset['Age'] <= 17), 'Age'] = 0.4\n",
    "    dataset.loc[(dataset['Age'] >17) & (dataset['Age'] <= 21), 'Age'] = 0.8\n",
    "    dataset.loc[(dataset['Age'] >21) & (dataset['Age'] <= 28), 'Age'] = 1.2\n",
    "    dataset.loc[(dataset['Age'] >28) & (dataset['Age'] <= 32), 'Age'] = 1.6\n",
    "    dataset.loc[(dataset['Age'] >32) & (dataset['Age'] <= 45), 'Age'] = 2\n",
    "    dataset.loc[dataset['Age'] >45, 'Age'] = 2.4\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대부분 S embark 에서 탐 => fillna('S')\n",
    "\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "test['Embarked'] = test['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mapping = {'S':0, 'C':1, 'Q':2}\n",
    "train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "test['Embarked'] = test['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(\n",
    "    test.groupby('Pclass')['Fare'].transform('median'), inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Fare'].isnull().sum(), test['Fare'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticket_num in train['Ticket'].unique():\n",
    "    train.loc[train['Ticket']==ticket_num,'group_size'] = len(train[train['Ticket']==ticket_num])\n",
    "\n",
    "for ticket_num in test['Ticket'].unique():\n",
    "    test.loc[test['Ticket']==ticket_num,'group_size'] = len(test[test['Ticket']==ticket_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare']/train['group_size']\n",
    "test['Fare'] = test['Fare']/test['group_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train,test]\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset.loc[dataset['group_size'] == 1, 'group_size'] = 0\n",
    "    dataset.loc[dataset['group_size'] == 2, 'group_size'] = 0.4\n",
    "    dataset.loc[(dataset['group_size'] == 3) | (dataset['group_size'] == 4), 'group_size'] = 0.8\n",
    "    dataset.loc[dataset['group_size'] > 4, 'group_size'] = 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train,test]\n",
    "for dataset in train_test_data:\n",
    "\n",
    "    dataset.loc[dataset['Fare'] <= 7,'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] >7) & (dataset['Fare'] <=8.8), 'Fare'] = 0.4\n",
    "    dataset.loc[(dataset['Fare'] >8.8) & (dataset['Fare'] <=17), 'Fare'] = 0.8\n",
    "    dataset.loc[(dataset['Fare'] >17) & (dataset['Fare'] <=30), 'Fare'] = 1.2\n",
    "    dataset.loc[(dataset['Fare'] >30) & (dataset['Fare'] <=100), 'Fare'] = 1.6\n",
    "    dataset.loc[dataset['Fare'] > 100,'Fare'] = 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hase Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "test.loc[test['Cabin'].isnull(), 'Null_Cabin'] = 0\n",
    "\n",
    "train.loc[train['Cabin'].notnull(), 'Null_Cabin'] = 1\n",
    "test.loc[test['Cabin'].notnull(), 'Null_Cabin'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Null_Cabin'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'] = train['Cabin'].str[:1]\n",
    "test['Cabin'] = test['Cabin'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\n",
    "\n",
    "train['Cabin'] = train['Cabin'].map(cabin_mapping)\n",
    "test['Cabin'] = test['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[test['Pclass']==3,'Cabin']=test.loc[test['Pclass']==3,'Cabin'].fillna(2.2)\n",
    "# test.loc[test['Pclass']==3,'Cabin']=test.loc[test['Pclass']==3,'Cabin'].fillna(2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill missing Fare with median fare for each Pclass\n",
    "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "test[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train,test]\n",
    "for dataset in train_test_data:\n",
    "\n",
    "    dataset.loc[dataset['FamilySize'] == 1,'FamilySize'] = 0.4\n",
    "    dataset.loc[(dataset['FamilySize'] == 2), 'FamilySize'] = 0.8\n",
    "    dataset.loc[(dataset['FamilySize'] == 3), 'FamilySize'] = 1.2\n",
    "    dataset.loc[dataset['FamilySize'] > 3,'FamilySize'] = 1.6\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['Ticket','SibSp','Parch','Name']\n",
    "train = train.drop(features_drop,axis=1)\n",
    "test = test.drop(features_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (891,))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.drop('Survived',axis=1)\n",
    "target = train['Survived']\n",
    "\n",
    "train_data.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Null_Age</th>\n",
       "      <th>group_size</th>\n",
       "      <th>Null_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.437321</td>\n",
       "      <td>0.864115</td>\n",
       "      <td>1.687081</td>\n",
       "      <td>0.464115</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>0.794258</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.217703</td>\n",
       "      <td>0.677512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.645772</td>\n",
       "      <td>0.496418</td>\n",
       "      <td>0.563371</td>\n",
       "      <td>0.685516</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.404727</td>\n",
       "      <td>0.257404</td>\n",
       "      <td>0.413179</td>\n",
       "      <td>0.395079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Sex         Age        Fare   \n",
       "count   418.000000  418.000000  418.000000  418.000000  418.000000  \\\n",
       "mean   1100.500000    2.265550    0.363636    1.437321    0.864115   \n",
       "std     120.810458    0.841838    0.481622    0.645772    0.496418   \n",
       "min     892.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "25%     996.250000    1.000000    0.000000    1.200000    0.400000   \n",
       "50%    1100.500000    3.000000    0.000000    1.600000    0.800000   \n",
       "75%    1204.750000    3.000000    1.000000    2.000000    1.200000   \n",
       "max    1309.000000    3.000000    1.000000    2.400000    2.000000   \n",
       "\n",
       "            Cabin    Embarked       Title    Null_Age  group_size  Null_Cabin   \n",
       "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000  \\\n",
       "mean     1.687081    0.464115    2.454545    0.794258    0.127273    0.217703   \n",
       "std      0.563371    0.685516    0.907782    0.404727    0.257404    0.413179   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.600000    0.000000    2.000000    1.000000    0.000000    0.000000   \n",
       "50%      2.000000    0.000000    3.000000    1.000000    0.000000    0.000000   \n",
       "75%      2.000000    1.000000    3.000000    1.000000    0.000000    0.000000   \n",
       "max      2.400000    2.000000    4.000000    1.000000    1.200000    1.000000   \n",
       "\n",
       "       FamilySize  \n",
       "count  418.000000  \n",
       "mean     0.677512  \n",
       "std      0.395079  \n",
       "min      0.400000  \n",
       "25%      0.400000  \n",
       "50%      0.400000  \n",
       "75%      0.800000  \n",
       "max      1.600000  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 400, 'random_state': 55}\n",
      "0.8294080723118448\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "parameters = {'n_estimators':[400,500]\n",
    "              ,'max_depth':[4,6,8]\n",
    "              ,'min_samples_split':[2,4,6]\n",
    "              ,'min_samples_leaf' : [2,4,6]\n",
    "              , 'random_state':[32,49]\n",
    "              }\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "grid_clf = GridSearchCV(rf_clf,param_grid=parameters,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "\n",
    "grid_clf.fit(train_data,target)\n",
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=400\n",
    "                             , max_depth=6\n",
    "                             ,min_samples_split=6\n",
    "                             ,min_samples_leaf=2\n",
    "                             , random_state=55)\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "prediction = clf.predict(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.062 0.07  0.264 0.055 0.066 0.067 0.023 0.244 0.008 0.055 0.042 0.043]\n",
      "PassengerId : 0.062\n",
      "Survived : 0.070\n",
      "Pclass : 0.264\n",
      "Sex : 0.055\n",
      "Age : 0.066\n",
      "Fare : 0.067\n",
      "Cabin : 0.023\n",
      "Embarked : 0.244\n",
      "Title : 0.008\n",
      "Null_Age : 0.055\n",
      "group_size : 0.042\n",
      "Null_Cabin : 0.043\n"
     ]
    }
   ],
   "source": [
    "# feature importance 추출\n",
    "\n",
    "print(\"Feature importances:\\n{0}\".format(np.round(clf.feature_importances_,3)))\n",
    "\n",
    "# feature 별 importance 매핑\n",
    "\n",
    "for name, value in zip(train.columns\n",
    "                       ,clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_a = pd.read_csv('../data/submission_a.csv')\n",
    "del submission_a['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822966507177034"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(prediction, submission_a)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7822966507177034\n",
      "1 0.7870813397129187\n",
      "2 0.7751196172248804\n",
      "3 0.7727272727272727\n",
      "4 0.7799043062200957\n",
      "5 0.777511961722488\n",
      "6 0.7870813397129187\n",
      "7 0.7799043062200957\n",
      "8 0.7822966507177034\n",
      "9 0.7751196172248804\n",
      "10 0.7727272727272727\n",
      "11 0.784688995215311\n",
      "12 0.7727272727272727\n",
      "13 0.7799043062200957\n",
      "14 0.777511961722488\n",
      "15 0.7799043062200957\n",
      "16 0.7799043062200957\n",
      "17 0.784688995215311\n",
      "18 0.7751196172248804\n",
      "19 0.7799043062200957\n",
      "20 0.7727272727272727\n",
      "21 0.784688995215311\n",
      "22 0.784688995215311\n",
      "23 0.7679425837320574\n",
      "24 0.784688995215311\n",
      "25 0.7727272727272727\n",
      "26 0.7655502392344498\n",
      "27 0.7870813397129187\n",
      "28 0.7942583732057417\n",
      "29 0.784688995215311\n",
      "30 0.7751196172248804\n",
      "31 0.7822966507177034\n",
      "32 0.7870813397129187\n",
      "33 0.777511961722488\n",
      "34 0.7822966507177034\n",
      "35 0.7822966507177034\n",
      "36 0.7870813397129187\n",
      "37 0.7727272727272727\n",
      "38 0.777511961722488\n",
      "39 0.777511961722488\n",
      "40 0.7870813397129187\n",
      "41 0.7822966507177034\n",
      "42 0.7822966507177034\n",
      "43 0.7751196172248804\n",
      "44 0.7870813397129187\n",
      "45 0.777511961722488\n",
      "46 0.7822966507177034\n",
      "47 0.7799043062200957\n",
      "48 0.7751196172248804\n",
      "49 0.7799043062200957\n",
      "50 0.784688995215311\n",
      "51 0.7727272727272727\n",
      "52 0.784688995215311\n",
      "53 0.7799043062200957\n",
      "54 0.7966507177033493\n",
      "55 0.7751196172248804\n",
      "56 0.7870813397129187\n",
      "57 0.7799043062200957\n",
      "58 0.777511961722488\n",
      "59 0.7894736842105263\n",
      "60 0.784688995215311\n",
      "61 0.784688995215311\n",
      "62 0.7822966507177034\n",
      "63 0.7727272727272727\n",
      "64 0.7822966507177034\n",
      "65 0.7703349282296651\n",
      "66 0.777511961722488\n",
      "67 0.7822966507177034\n",
      "68 0.777511961722488\n",
      "69 0.7822966507177034\n",
      "70 0.7799043062200957\n",
      "71 0.7751196172248804\n",
      "72 0.7918660287081339\n",
      "73 0.784688995215311\n",
      "74 0.7799043062200957\n",
      "75 0.777511961722488\n",
      "76 0.784688995215311\n",
      "77 0.7822966507177034\n",
      "78 0.7751196172248804\n",
      "79 0.784688995215311\n",
      "80 0.7799043062200957\n",
      "81 0.784688995215311\n",
      "82 0.7870813397129187\n",
      "83 0.7799043062200957\n",
      "84 0.777511961722488\n",
      "85 0.7799043062200957\n",
      "86 0.7751196172248804\n",
      "87 0.777511961722488\n",
      "88 0.7727272727272727\n",
      "89 0.784688995215311\n",
      "90 0.7870813397129187\n",
      "91 0.777511961722488\n",
      "92 0.777511961722488\n",
      "93 0.7727272727272727\n",
      "94 0.7799043062200957\n",
      "95 0.7751196172248804\n",
      "96 0.777511961722488\n",
      "97 0.784688995215311\n",
      "98 0.7799043062200957\n",
      "99 0.777511961722488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54, 0.7966507177033493)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list=[]\n",
    "\n",
    "for r in range(100):\n",
    "    clf = RandomForestClassifier(n_estimators=400, max_depth=8, min_samples_split=6, min_samples_leaf=2, random_state=r, n_jobs=-1)\n",
    "    clf.fit(train_data, target) # 학습\n",
    "    Y_pred = clf.predict(test) # 테스트 데이터로 예측값 추출    \n",
    "    \n",
    "    accuracy = accuracy_score(Y_pred, submission_a)\n",
    "    print(r, accuracy)\n",
    "    acc_list.append(accuracy)\n",
    "\n",
    "acc_list.index(max(acc_list)),max(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=400\n",
    "                             , max_depth=8\n",
    "                             ,min_samples_split=6\n",
    "                             ,min_samples_leaf=2\n",
    "                             , random_state=54\n",
    "                             ,n_jobs=-1)\n",
    "clf.fit(train_data, target)\n",
    "\n",
    "prediction = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7966507177033493"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(prediction, submission_a)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "\n",
    "    'PassengerId':test['PassengerId']\n",
    "    ,'Survived':prediction\n",
    "    \n",
    "})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
